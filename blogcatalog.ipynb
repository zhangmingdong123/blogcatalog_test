{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.1 in ./venv/bin/python/lib/python3.10/site-packages (2.0.1)\r\n",
      "Requirement already satisfied: sympy in ./venv/bin/python/lib/python3.10/site-packages (from torch==2.0.1) (1.12)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/bin/python/lib/python3.10/site-packages (from torch==2.0.1) (3.1.2)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/bin/python/lib/python3.10/site-packages (from torch==2.0.1) (4.7.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/bin/python/lib/python3.10/site-packages (from torch==2.0.1) (3.12.2)\r\n",
      "Requirement already satisfied: networkx in ./venv/bin/python/lib/python3.10/site-packages (from torch==2.0.1) (3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/bin/python/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/bin/python/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\r\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 23.1.2 is available.\r\n",
      "You should consider upgrading via the '/Users/jasonzhao/PycharmProjects/blogcatalog/venv/bin/python/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: numpy==1.24.3 in ./venv/bin/python/lib/python3.10/site-packages (1.24.3)\r\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 23.1.2 is available.\r\n",
      "You should consider upgrading via the '/Users/jasonzhao/PycharmProjects/blogcatalog/venv/bin/python/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in ./venv/bin/python/lib/python3.10/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/bin/python/lib/python3.10/site-packages (from scikit-learn==1.3.0) (1.3.1)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/bin/python/lib/python3.10/site-packages (from scikit-learn==1.3.0) (1.11.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/bin/python/lib/python3.10/site-packages (from scikit-learn==1.3.0) (1.24.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/bin/python/lib/python3.10/site-packages (from scikit-learn==1.3.0) (3.1.0)\r\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 23.1.2 is available.\r\n",
      "You should consider upgrading via the '/Users/jasonzhao/PycharmProjects/blogcatalog/venv/bin/python/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: torch-geometric==2.3.1 in ./venv/bin/python/lib/python3.10/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (5.9.5)\r\n",
      "Requirement already satisfied: numpy in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.24.3)\r\n",
      "Requirement already satisfied: tqdm in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (4.65.0)\r\n",
      "Requirement already satisfied: scipy in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.11.1)\r\n",
      "Requirement already satisfied: scikit-learn in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.3.0)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (3.1.2)\r\n",
      "Requirement already satisfied: requests in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (2.31.0)\r\n",
      "Requirement already satisfied: pyparsing in ./venv/bin/python/lib/python3.10/site-packages (from torch-geometric==2.3.1) (3.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/bin/python/lib/python3.10/site-packages (from jinja2->torch-geometric==2.3.1) (2.1.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/bin/python/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/bin/python/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (3.2.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/bin/python/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (2023.5.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/bin/python/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (2.0.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/bin/python/lib/python3.10/site-packages (from scikit-learn->torch-geometric==2.3.1) (1.3.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/bin/python/lib/python3.10/site-packages (from scikit-learn->torch-geometric==2.3.1) (3.1.0)\r\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 23.1.2 is available.\r\n",
      "You should consider upgrading via the '/Users/jasonzhao/PycharmProjects/blogcatalog/venv/bin/python/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Pip Install If you do not have these packages\n",
    "# Python version = 3.10\n",
    "!pip install torch==2.0.1\n",
    "!pip install numpy==1.24.3\n",
    "!pip install scikit-learn==1.3.0\n",
    "!pip install torch-geometric==2.3.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# read the actual graph from network.txt\n",
    "# assuming the graph is undirected\n",
    "def read_graph():\n",
    "    with open('graphs.npz', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    edges = []\n",
    "    for line in lines[1:]:\n",
    "        node1, node2 = map(int, line.split())\n",
    "        edges.append((node1, node2))  # Add both directions to make the graph undirected\n",
    "        edges.append((node2, node1))\n",
    "\n",
    "    edge_index = torch.tensor(edges).t().contiguous()\n",
    "    return edge_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# read the true labels for the nodes\n",
    "# same format as the input obtained from read_features\n",
    "def read_labels(file_path):\n",
    "    num_nodes = 10312\n",
    "    num_labels = 39\n",
    "    labels = torch.zeros((num_nodes, num_labels), dtype=torch.float)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Skip the first line\n",
    "        next(file)\n",
    "        for line in file:\n",
    "            node, *label = map(int, line.strip().split())\n",
    "            for l in label:\n",
    "                labels[node][l] = 1  # set the label position to 1\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# The Graph Convolutional Network\n",
    "# Need refinement and fine tuning of hyperparameters\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, num_intermediate_features=64, dropout_rate=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # 4 convolutional layers, with dropout in between, and a final linear classifier\n",
    "        self.conv1 = GCNConv(num_node_features, num_intermediate_features)\n",
    "        self.conv2 = GCNConv(num_intermediate_features, num_intermediate_features)\n",
    "        self.conv3 = GCNConv(num_intermediate_features, num_intermediate_features)\n",
    "        self.conv4 = GCNConv(num_intermediate_features, num_intermediate_features)\n",
    "        self.classifier = Linear(num_intermediate_features, num_classes)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # forward pass, apply the convolutions, and relu\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Final GNN embedding space.\n",
    "        out = self.classifier(x)\n",
    "\n",
    "        return out, x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6928028464317322, f1: 0.06521590974621365\n",
      "Epoch: 1, Loss: 0.6901902556419373, f1: 0.059343076049943246\n",
      "Epoch: 2, Loss: 0.687747597694397, f1: 0.06467518198049718\n",
      "Epoch: 3, Loss: 0.6849347949028015, f1: 0.06879105137231595\n",
      "Epoch: 4, Loss: 0.6814907789230347, f1: 0.07258674141079542\n",
      "Epoch: 5, Loss: 0.677045464515686, f1: 0.0782207218388522\n",
      "Epoch: 6, Loss: 0.6713627576828003, f1: 0.0828932098619236\n",
      "Epoch: 7, Loss: 0.6641836762428284, f1: 0.09420823363396527\n",
      "Epoch: 8, Loss: 0.6551318168640137, f1: 0.10619200908918765\n",
      "Epoch: 9, Loss: 0.6440539956092834, f1: 0.11876884245951062\n",
      "Epoch: 10, Loss: 0.6310425400733948, f1: 0.1224390243902439\n",
      "Epoch: 11, Loss: 0.6160212755203247, f1: 0.11954868154158216\n",
      "Epoch: 12, Loss: 0.5991202592849731, f1: 0.10820231385345595\n",
      "Epoch: 13, Loss: 0.5804398655891418, f1: 0.09187655196878326\n",
      "Epoch: 14, Loss: 0.5599813461303711, f1: 0.06201727787630871\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m400\u001b[39m): \u001b[38;5;66;03m# Run 400 epochs\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     out, loss, h \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m test(data, out)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, f1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     25\u001b[0m out, h \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)  \u001b[38;5;66;03m# Perform a single forward pass.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out[data\u001b[38;5;241m.\u001b[39mtrain_mask],\n\u001b[1;32m     27\u001b[0m                  data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask]\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;66;03m# Compute the loss solely based on the training nodes.\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Derive gradients.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update parameters based on gradients.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, loss, h\n",
      "File \u001b[0;32m~/PycharmProjects/blogcatalog/venv/bin/python/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/blogcatalog/venv/bin/python/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# read the features\n",
    "x, train_mask, test_mask = read_features()\n",
    "# read the labels\n",
    "y = read_labels('blogcatalogue-group.txt')\n",
    "# read the graph\n",
    "edge_index = read_graph()\n",
    "# define the GCN Data class\n",
    "data = Data(x=x, y=y, edge_index=edge_index, train_mask=train_mask,test_mask=test_mask)\n",
    "\n",
    "\n",
    "model = GCN(num_node_features=data.num_node_features, num_classes=39) # Create the model\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Initialize the CrossEntropyLoss function.\n",
    "\n",
    "# all potential optimizers to try: SFG, ADAM, RMSprop\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)  # Initialize the Adam optimizer.\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0003)\n",
    "\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask],\n",
    "                     data.y[data.train_mask].float()) # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return out, loss, h\n",
    "\n",
    "def test(data, out):\n",
    "    model.eval() # evaluate model\n",
    "    out = torch.sigmoid(out) # use a sigmoid function to map result to probabilities\n",
    "    pred_labels = (out[train_mask] > 0.5).float()  # Directly use the output\n",
    "    true_labels = data.y[train_mask].float() # Obtain the true labels\n",
    "\n",
    "    f1 = f1_score(true_labels.cpu().numpy(), pred_labels.cpu().numpy(), average='micro') # Calculate F1 score\n",
    "\n",
    "    return f1\n",
    "\n",
    "for epoch in range(400): # Run 400 epochs\n",
    "    out, loss, h = train(data)\n",
    "    f1 = test(data, out)\n",
    "    print(f'Epoch: {epoch}, Loss: {loss}, f1: {f1}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}